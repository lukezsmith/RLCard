{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is largely a modified version of the original RLCard github repo: https://github.com/datamllab/rlcard.\n",
    "We also use and modify the ARM implementation provided in the accompanying code: https://github.com/kxinhe/LRM_FP of the following paper: \n",
    "\"He, H. Wu, Z. Wang, and H. Li, “Finding nash equilibrium\n",
    "for imperfect information games via fictitious play based on local regret minimization,” \n",
    "International Journal of Intelligent Systems, 2022\"\n",
    "in our NFSP-ARM implementation. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "\n",
    "import rlcard\n",
    "from rlcard.agents import RandomAgent\n",
    "from rlcard.models.leducholdem_rule_models import LeducHoldemRuleAgentV2\n",
    "\n",
    "from rlcard.utils import get_device, set_seed, tournament, tournament_winnings, reorganize, Logger, plot_winrate_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, algorithm, device, seed, num_episodes, num_eval_games, evaluate_every, save_every, log_dir, opposition_agent):\n",
    "\n",
    "    # hyperparameters I need to parameterise\n",
    "    csv_path = log_dir + opposition_agent + '_performance.csv'\n",
    "\n",
    "    # Seed numpy, torch, random\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Make the training environment with seed\n",
    "    env = rlcard.make(env, config={'seed': seed})\n",
    "\n",
    "    # Make the evaluation environment with seed\n",
    "    eval_env = rlcard.make(\"teamleducholdemv3\", config={'seed': seed})\n",
    "\n",
    "    # Initialize the agents\n",
    "    if algorithm == \"NFSP\":\n",
    "        from rlcard.agents import NFSPAgent\n",
    "        agents = []\n",
    "\n",
    "        # create NFSP agents\n",
    "        for i in range(env.num_players):\n",
    "            agent = NFSPAgent(num_actions=env.num_actions,\n",
    "                              state_shape=env.state_shape[0],\n",
    "                              hidden_layers_sizes=[64, 64],\n",
    "                              q_mlp_layers=[64, 64],\n",
    "                              device=device)\n",
    "            agents.append(agent)\n",
    "    elif algorithm == \"NFSP-ARM\":\n",
    "        from rlcard.agents import NFSPARMAgent\n",
    "        agents = []\n",
    "\n",
    "        # create NFSP-ARM agents\n",
    "        for i in range(env.num_players):\n",
    "            agent = NFSPARMAgent(num_actions=env.num_actions,\n",
    "                                 state_shape=env.state_shape[0],\n",
    "                                 hidden_layers_sizes=[64, 64],\n",
    "                                 q_mlp_layers=[64, 64],\n",
    "                                 device=device)\n",
    "            agents.append(agent)\n",
    "\n",
    "    elif algorithm == \"DQN\":\n",
    "        from rlcard.agents import DQNAgent\n",
    "        agents = []\n",
    "\n",
    "        # create DQN agents\n",
    "        for i in range(env.num_players):\n",
    "            agent = DQNAgent(num_actions=env.num_actions,\n",
    "                             state_shape=env.state_shape[0],\n",
    "                             mlp_layers=[64, 64],\n",
    "                             device=device)\n",
    "            agents.append(agent)\n",
    "    else:\n",
    "        agents = []\n",
    "\n",
    "        # create DQN agents\n",
    "        for i in range(env.num_players):\n",
    "            agent = DQNAgent(num_actions=env.num_actions,\n",
    "                             state_shape=env.state_shape[0],\n",
    "                             mlp_layers=[64, 64],\n",
    "                             device=device)\n",
    "            agents.append(agent)\n",
    "\n",
    "    # assign training agent distribution\n",
    "    env.set_agents(agents)\n",
    "\n",
    "    if opposition_agent == \"rule-based\":\n",
    "        # create rule-based agents for evaluation\n",
    "        eval_agent_1 = LeducHoldemRuleAgentV2()\n",
    "        eval_agent_2 = LeducHoldemRuleAgentV2()\n",
    "\n",
    "    else:\n",
    "        # create random agents for evaluation\n",
    "        eval_agent_1 = RandomAgent(num_actions=env.num_actions)\n",
    "        eval_agent_2 = RandomAgent(num_actions=env.num_actions)\n",
    "    \n",
    "    # assign evaluation agent distribution\n",
    "    eval_env.set_agents([agents[0], eval_agent_1, agents[2], eval_agent_2])\n",
    "\n",
    "    # Start training\n",
    "    with Logger(log_dir ,opposition_agent) as logger:\n",
    "        for episode in range(num_episodes):\n",
    "\n",
    "            # sample policy for episode for each\n",
    "            for agent in agents:\n",
    "                agent.sample_episode_policy()\n",
    "\n",
    "            # Generate data from the environment\n",
    "            trajectories, payoffs, _ = env.run(is_training=True)\n",
    "\n",
    "            # Reorganaize the data to be state, action, reward, next_state, done\n",
    "            trajectories = reorganize(trajectories, payoffs)\n",
    "\n",
    "            # Feed transitions into agent memory, and train the agent\n",
    "            # Here, we assume that DQN always plays the first position\n",
    "            # and the other players play randomly (if any)\n",
    "            for i in range(env.num_players):\n",
    "                for ts in trajectories[i]:\n",
    "                    agents[i].feed(ts)\n",
    "\n",
    "            # Evaluate win rate performance against opposition evaluation agents\n",
    "            if episode % evaluate_every == 0:\n",
    "                payoffs, winnings = tournament_winnings(eval_env, num_eval_games)\n",
    "                logger.log_winrate(\n",
    "                    env.timestep, payoffs[0] + payoffs[2], winnings[0])\n",
    "\n",
    "            # Make plot\n",
    "            if episode % save_every == 0 and episode > 0:\n",
    "                # Save model\n",
    "                save_path = os.path.join(log_dir, opposition_agent +'_model.pth')\n",
    "                torch.save(agents[0], save_path)\n",
    "            csv_path, fig_path = logger.csv_path, logger.fig_path\n",
    "    # plot win rate curve\n",
    "    plot_winrate_curve(csv_path, fig_path, algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Running on the CPU\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  11\n",
      "  reward       |  0.1791547169811729\n",
      "  winrate      |  0.5407169811320754\n",
      "----------------------------------------\n",
      "INFO - Step 100, rl-loss: 1.4461621046066284\n",
      "INFO - Copied model beep parameters to target network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/mkkq27/final-env_v11/lib/python3.8/site-packages/rlcard/agents/dqn_agent.py:195: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  state_batch, action_batch, reward_batch, next_state_batch, legal_actions_batch, done_batch = self.memory.sample()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 100, rl-loss: 0.8985109329223633\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 100, rl-loss: 0.7837046980857849\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 100, rl-loss: 0.9936385154724121\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 1100, rl-loss: 3.7275242805480957\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 1100, rl-loss: 2.6592292785644535\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 1096, sl-loss: None60113430023193\n",
      "----------------------------------------\n",
      "  timestep     |  4409\n",
      "  reward       |  0.16255094339626444\n",
      "  winrate      |  0.5369433962264151\n",
      "----------------------------------------\n",
      "INFO - Step 1100, rl-loss: 3.5663781166076665\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 1100, rl-loss: 6.23044061660766647\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 2100, rl-loss: 0.96490144729614265\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 2100, rl-loss: 4.4470510482788097\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 2100, rl-loss: 1.97146999835968027\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 2100, rl-loss: 1.65611732006073854\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 2211, sl-loss: 0.60591542720794687\n",
      "----------------------------------------\n",
      "  timestep     |  9164\n",
      "  reward       |  0.9595320754716331\n",
      "  winrate      |  0.7180754716981133\n",
      "----------------------------------------\n",
      "INFO - Step 3100, rl-loss: 3.42002630233764656\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 3100, rl-loss: 1.83905768394470214\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 3100, rl-loss: 1.21402394771575933\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 3100, rl-loss: 0.75131922960281373\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 4100, rl-loss: 2.04190993309021194\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 3604, sl-loss: 0.64009541273117077\n",
      "----------------------------------------\n",
      "  timestep     |  15047\n",
      "  reward       |  0.9558792452829745\n",
      "  winrate      |  0.7172452830188679\n",
      "----------------------------------------\n",
      "INFO - Step 4100, rl-loss: 1.2021620273590088\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 4100, rl-loss: 3.37101221084594734\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 5100, rl-loss: 3.75806808471679777\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 4100, rl-loss: 1.66002845764160165\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 5100, rl-loss: 1.35279917716979987\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 4961, sl-loss: 0.69483548402786253\n",
      "----------------------------------------\n",
      "  timestep     |  20930\n",
      "  reward       |  0.9774641509434017\n",
      "  winrate      |  0.7221509433962264\n",
      "----------------------------------------\n",
      "INFO - Step 5100, rl-loss: 1.0763964653015137\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 6100, rl-loss: 8.24975776672363345\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 6100, rl-loss: 1.11838245391845735\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 5100, rl-loss: 2.44764018058776865\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 7100, rl-loss: 12.2770347595214847\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 6100, rl-loss: 2.33633089065551767\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 6311, sl-loss: 0.7610090374946594\n",
      "----------------------------------------\n",
      "  timestep     |  26690\n",
      "  reward       |  0.9454188679245137\n",
      "  winrate      |  0.7148679245283018\n",
      "----------------------------------------\n",
      "INFO - Step 7100, rl-loss: 6.3888421058654785\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 6100, rl-loss: 1.9589384794235235\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 8100, rl-loss: 11.6496267318725597\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 7100, rl-loss: 10.3657617568969733\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 8100, rl-loss: 4.04906272888183696\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 7100, rl-loss: 3.39002084732055667\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 7648, sl-loss: 0.7463020682334995\n",
      "----------------------------------------\n",
      "  timestep     |  32391\n",
      "  reward       |  0.8804981132075083\n",
      "  winrate      |  0.7001132075471698\n",
      "----------------------------------------\n",
      "INFO - Step 9100, rl-loss: 4.28110504150390677\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 8100, rl-loss: 4.42834424972534284\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 9100, rl-loss: 2.9563262462615967\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 10100, rl-loss: 2.4830980300903325\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 8100, rl-loss: 1.24656045436859134\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 8948, sl-loss: 0.77486550807952886\n",
      "----------------------------------------\n",
      "  timestep     |  38000\n",
      "  reward       |  0.8305207547169097\n",
      "  winrate      |  0.6887547169811321\n",
      "----------------------------------------\n",
      "INFO - Step 10100, rl-loss: 3.9061410427093506\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 9100, rl-loss: 7.174927711486816835\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 11100, rl-loss: 1.12484431266784676\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 9100, rl-loss: 2.00182580947875984\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 11100, rl-loss: 1.16706979274749766\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 10100, rl-loss: 3.84511375427246175\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 10181, sl-loss: 0.81016248464584355\n",
      "----------------------------------------\n",
      "  timestep     |  43690\n",
      "  reward       |  0.7802113207546268\n",
      "  winrate      |  0.6773207547169812\n",
      "----------------------------------------\n",
      "INFO - Step 12100, rl-loss: 1.91209614276885994\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 10100, rl-loss: 4.75123167037963987\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 12100, rl-loss: 1.13329088687896733\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 11100, rl-loss: 5.29029226303100616\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 13100, rl-loss: 1.6062009334564219\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 11100, rl-loss: 5.42921066284179723\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 11467, sl-loss: 0.82843792438507084\n",
      "----------------------------------------\n",
      "  timestep     |  49288\n",
      "  reward       |  0.8107622641508642\n",
      "  winrate      |  0.6842641509433962\n",
      "----------------------------------------\n",
      "INFO - Step 13100, rl-loss: 1.36104810237884523\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 12100, rl-loss: 6.96171188354492295\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 14100, rl-loss: 11.740527153015137\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 12100, rl-loss: 1.4762300252914429\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 14100, rl-loss: 0.92523455619812016\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 12680, sl-loss: 0.89740705490112325\n",
      "----------------------------------------\n",
      "  timestep     |  54933\n",
      "  reward       |  0.7674264150942325\n",
      "  winrate      |  0.6744150943396227\n",
      "----------------------------------------\n",
      "INFO - Step 13100, rl-loss: 5.0614404678344738\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 15100, rl-loss: 6.27275466918945363\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 13100, rl-loss: 1.85868573188781745\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 15100, rl-loss: 6.73047590255737353\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 14100, rl-loss: 3.05652904510498057\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 16100, rl-loss: 5.4822883605957038\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 13961, sl-loss: 0.8311533331871033\n",
      "----------------------------------------\n",
      "  timestep     |  60366\n",
      "  reward       |  0.7119698113206175\n",
      "  winrate      |  0.6618113207547169\n",
      "----------------------------------------\n",
      "INFO - Step 16100, rl-loss: 12.240166664123535\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 14100, rl-loss: 1.6346068382263184\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 15100, rl-loss: 6.47268915176391615\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 17100, rl-loss: 0.59711092710495753\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 17100, rl-loss: 9.26021957397461996\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 15100, rl-loss: 12.5920181274414066\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 15152, sl-loss: 0.77667623758316046\n",
      "----------------------------------------\n",
      "  timestep     |  65863\n",
      "  reward       |  0.7644377358489518\n",
      "  winrate      |  0.6737358490566038\n",
      "----------------------------------------\n",
      "INFO - Step 16100, rl-loss: 2.20239567756652837\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 18100, rl-loss: 1.32819318771362317\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 18100, rl-loss: 6.7616515159606931\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 16100, rl-loss: 7.2380871772766111\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 17100, rl-loss: 21.4150104522705086\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 16423, sl-loss: 0.85224843025207526\n",
      "----------------------------------------\n",
      "  timestep     |  71668\n",
      "  reward       |  0.8100981132074568\n",
      "  winrate      |  0.6841132075471699\n",
      "----------------------------------------\n",
      "INFO - Step 19100, rl-loss: 4.2486643791198736\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 19100, rl-loss: 5.2546548843383795\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 17100, rl-loss: 1.53129005432128934\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 18100, rl-loss: 5.65373563766479545\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 20100, rl-loss: 1.79100203514099127\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 20100, rl-loss: 1.13317525386810386\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 17625, sl-loss: 0.83221054077148443\n",
      "----------------------------------------\n",
      "  timestep     |  77154\n",
      "  reward       |  0.7893433962263262\n",
      "  winrate      |  0.6793962264150943\n",
      "----------------------------------------\n",
      "INFO - Step 19100, rl-loss: 5.21303510665893556\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 21100, rl-loss: 2.4436810016632081\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 18100, rl-loss: 0.9080777168273926\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 21100, rl-loss: 1.26507890224456793\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 18827, sl-loss: 0.82360839843751325\n",
      "----------------------------------------\n",
      "  timestep     |  82461\n",
      "  reward       |  0.7953207547168696\n",
      "  winrate      |  0.6807547169811321\n",
      "----------------------------------------\n",
      "INFO - Step 20100, rl-loss: 3.1827697753906256\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 22100, rl-loss: 2.61926960945129455\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 19100, rl-loss: 2.6910285949707032\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 22100, rl-loss: 1.65188622474670446\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 21100, rl-loss: 0.58650732040405274\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 23100, rl-loss: 2.45296931266784678\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 20064, sl-loss: 0.85668647289276124\n",
      "----------------------------------------\n",
      "  timestep     |  87807\n",
      "  reward       |  0.7735698113206504\n",
      "  winrate      |  0.675811320754717\n",
      "----------------------------------------\n",
      "INFO - Step 20100, rl-loss: 1.50170874595642183\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 23100, rl-loss: 1.35179448127746584\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 22100, rl-loss: 1.52773046493530277\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 24100, rl-loss: 3.42992663383483914\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 21100, rl-loss: 1.53659570217132577\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 24100, rl-loss: 0.79463326930999765\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 21365, sl-loss: 0.8515862226486206\n",
      "----------------------------------------\n",
      "  timestep     |  93388\n",
      "  reward       |  0.7828679245281966\n",
      "  winrate      |  0.6779245283018868\n",
      "----------------------------------------\n",
      "INFO - Step 23100, rl-loss: 2.3524906635284424\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 25100, rl-loss: 1.3403316736221313\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 25100, rl-loss: 1.86431825160980223\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 22100, rl-loss: 3.4239668846130373\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 26100, rl-loss: 10.7325935363769536\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 24100, rl-loss: 1.7997661828994754\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 22614, sl-loss: 0.88734978437423715\n",
      "----------------------------------------\n",
      "  timestep     |  98910\n",
      "  reward       |  0.7607849056602689\n",
      "  winrate      |  0.6729056603773584\n",
      "----------------------------------------\n",
      "INFO - Step 26100, rl-loss: 1.33304357528686525\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 23100, rl-loss: 3.78309726715087917\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 25100, rl-loss: 0.7938211560249329\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 27100, rl-loss: 0.8862706422805786\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 23886, sl-loss: 0.92375904321670536\n",
      "----------------------------------------\n",
      "  timestep     |  104457\n",
      "  reward       |  0.7388679245281803\n",
      "  winrate      |  0.6679245283018868\n",
      "----------------------------------------\n",
      "INFO - Step 27100, rl-loss: 2.2536504268646243\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 24100, rl-loss: 2.43569588661193855\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 28100, rl-loss: 0.93547266721725464\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 26100, rl-loss: 1.60972857475280763\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 28100, rl-loss: 1.68894636631011964\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 27100, rl-loss: 1.3341425657272339\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 29100, rl-loss: 2.0069038867950442\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 25076, sl-loss: 0.9054588079452515\n",
      "----------------------------------------\n",
      "  timestep     |  110121\n",
      "  reward       |  0.7534792452829051\n",
      "  winrate      |  0.6712452830188679\n",
      "----------------------------------------\n",
      "INFO - Step 25100, rl-loss: 4.5038762092590335\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 29100, rl-loss: 3.46332430839538574\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 30100, rl-loss: 4.56187677383422853\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 28100, rl-loss: 1.8506755828857422\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 26100, rl-loss: 3.68313980102539064\n",
      "INFO - Copied model beep parameters to target network.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 26263, sl-loss: 0.9162411689758301\n",
      "----------------------------------------\n",
      "  timestep     |  115706\n",
      "  reward       |  0.8056150943395479\n",
      "  winrate      |  0.6830943396226415\n",
      "----------------------------------------\n",
      "INFO - Step 30100, rl-loss: 0.6461005210876465\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 31100, rl-loss: 4.42616653442382815\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 29100, rl-loss: 1.0930424928665161\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 27100, rl-loss: 1.86103367805480963\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 31100, rl-loss: 1.76033687591552734\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 32100, rl-loss: 5.31660366058349617\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 30100, rl-loss: 1.7237988710403442\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 27530, sl-loss: 0.8573567867279053\n",
      "----------------------------------------\n",
      "  timestep     |  121302\n",
      "  reward       |  0.7861886792451942\n",
      "  winrate      |  0.6786792452830188\n",
      "----------------------------------------\n",
      "INFO - Step 28100, rl-loss: 10.7467060089111335\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 32100, rl-loss: 4.0124130249023444\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 33100, rl-loss: 1.83777308464050325\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 31100, rl-loss: 1.2675123214721689\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 28810, sl-loss: 0.85566365718841554\n",
      "----------------------------------------\n",
      "  timestep     |  126671\n",
      "  reward       |  0.8087698113206782\n",
      "  winrate      |  0.683811320754717\n",
      "----------------------------------------\n",
      "INFO - Step 29100, rl-loss: 1.22058308124542246\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 33100, rl-loss: 5.1647529602050787\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 34100, rl-loss: 2.59222841262817455\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 32100, rl-loss: 3.30386495590209965\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 30100, rl-loss: 2.76608467102050855\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 34100, rl-loss: 7.1170859336853033\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 30186, sl-loss: 0.8723741769790649\n",
      "----------------------------------------\n",
      "  timestep     |  132293\n",
      "  reward       |  0.7601207547168805\n",
      "  winrate      |  0.6727547169811321\n",
      "----------------------------------------\n",
      "INFO - Step 35100, rl-loss: 3.5327241420745853\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 33100, rl-loss: 1.84548020362854995\n",
      "INFO - Copied model beep parameters to target network.\n",
      "INFO - Step 35309, rl-loss: 5.2896976470947278"
     ]
    }
   ],
   "source": [
    "import time\n",
    "env = \"teamleducholdemv3\"\n",
    "algorithm = \"NFSP\"\n",
    "\n",
    "# hyperparameters\n",
    "device = get_device()\n",
    "seed = 42\n",
    "num_episodes = 15000\n",
    "num_eval_games = 26500\n",
    "evaluate_every = 525\n",
    "save_every = 50\n",
    "opposition_agent = 'random'\n",
    "log_dir = './'\n",
    "\n",
    "start = time.time()\n",
    "train(env, algorithm, device, seed, num_episodes,\n",
    "      num_eval_games, evaluate_every, save_every, log_dir, opposition_agent)\n",
    "end = time.time()\n",
    "print(end - start , ' seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-kernel_v11",
   "language": "python",
   "name": "final-kernel_v11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
